{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vI2kuiKRLkM"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naziv GPU-a:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nema GPU-a\")"
      ],
      "metadata": {
        "id": "LAPvIb6rRU46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools\n",
        "import datetime\n",
        "import cv2\n",
        "import os\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools\n",
        "import datetime\n",
        "import cv2\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n"
      ],
      "metadata": {
        "id": "FNon1Hk9RYmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "UN8DIvhnRvHS",
        "outputId": "3210caea-bad3-4b97-cd60-e25af1561636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-907070862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainTumorDataset(Dataset):\n",
        "    def __init__(self, root_dir, labels, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.image_labels = []\n",
        "        self.classes = labels\n",
        "\n",
        "        for label in labels:\n",
        "            folder = os.path.join(root_dir, label)\n",
        "            for filename in os.listdir(folder):\n",
        "                if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    continue\n",
        "\n",
        "                self.image_paths.append(os.path.join(folder, filename))\n",
        "                self.image_labels.append(labels.index(label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.image_labels[idx]\n",
        "\n",
        "        image = cv2.imread(img_path, 0)  # grayscale\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Image at path '{img_path}' could not be loaded.\")\n",
        "        image = cv2.bilateralFilter(image, 2, 50, 50)\n",
        "        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "gWcD546mRdhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 1. loadaj dataset\n",
        "full_dataset = BrainTumorDataset(\"/content/drive/My Drive/training\", labels, transform=transform)\n",
        "print(\"dataset size: \", len(full_dataset))\n",
        "\n",
        "indices = list(range(len(full_dataset)))\n",
        "\n",
        "# podjela dataseta u trening i validation(80%- 20%)\n",
        "train_indices, val_indices = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    stratify=full_dataset.image_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Subset(full_dataset, train_indices)\n",
        "val_dataset = Subset(full_dataset, val_indices)\n",
        "print(\"training dataset size: \", len(train_dataset))\n",
        "print(\"validation dataset size: \", len(val_dataset))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "jbSoDNEwRhSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/drive/My Drive/training\"\n",
        "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "for label in classes:\n",
        "    folder = os.path.join(root_dir, label)\n",
        "    num_images = sum(\n",
        "        fname.lower().endswith(('.jpg', '.jpeg', '.png')) for fname in os.listdir(folder)\n",
        "    )\n",
        "    print(f\"{label}: {num_images} images\")"
      ],
      "metadata": {
        "id": "Sl-YqwmhbA35",
        "outputId": "f025bc80-ad50-4589-a26b-530a6db3d9a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glioma: 1321 images\n",
            "meningioma: 1339 images\n",
            "notumor: 1595 images\n",
            "pituitary: 1457 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VIZUALIZACIJA\n",
        "data_iter = iter(train_loader)\n",
        "images, batch_labels = next(data_iter)\n",
        "#pretvaranje slike u numpy polje i normalizacija\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "images = (images.numpy().transpose((0, 2, 3, 1)) * std + mean).clip(0, 1)\n",
        "\n",
        "#vizualizacija\n",
        "num_images = len(images)\n",
        "rows = int(np.ceil(num_images / 4))\n",
        "fig, axes = plt.subplots(rows, 4, figsize=(15, 15))\n",
        "\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < num_images:\n",
        "        ax.imshow(images[i])\n",
        "        class_index = batch_labels[i].item()  # convert tensor to int\n",
        "        ax.set_title(f'Label: {train_dataset.dataset.classes[class_index]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SZ00HMjcSXOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_3ajvuJZ1-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTRH7ShuTfTs",
        "outputId": "9bc2d16d-0ff0-46a8-d7a8-98d422888f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs=15, name='model', patience=7):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    tolerance = 0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # === Training ===\n",
        "        model.train()\n",
        "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = 100 * correct_train / total_train\n",
        "\n",
        "        # === Validation ===\n",
        "        model.eval()\n",
        "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = 100 * correct_val / total_val\n",
        "\n",
        "        # === Logging ===\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # === Early Stopping ===\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), f'best_brain_tumor_{name}.pth')\n",
        "            tolerance = 0\n",
        "        else:\n",
        "            tolerance += 1\n",
        "            if tolerance >= patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs.\")\n",
        "                break\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "46f6McDpUKo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model2.fc.in_features\n",
        "model2.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 4)\n",
        ")\n",
        "\n",
        "model2 = model2.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "Qqw1_gCIS7fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model2.named_parameters():\n",
        "    if 'layer4' in name or 'layer3' in name or 'fc' in name:\n",
        "        param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "RExu4P1BgW8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model2.parameters()), lr=1e-4)"
      ],
      "metadata": {
        "id": "oilEyWSGgaLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "history = train_model(model2, train_loader, val_loader, criterion, optimizer, num_epochs=5, name='resnet18_finetuned')\n",
        "\n"
      ],
      "metadata": {
        "id": "FhiXN1Piga_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = model2.to(device)\n",
        "model2.eval()"
      ],
      "metadata": {
        "id": "l0930Cij9Hh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "test_dataset = BrainTumorDataset(\"/content/drive/My Drive/Testing\", class_names, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "print(\"test dataset size: \", len(test_dataset))\n"
      ],
      "metadata": {
        "id": "FcuOVmm1POqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563eaae5-90e4-4b80-f655-a05fbcf7d509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test dataset size:  1311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, num_images_to_show=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # ?\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_images.extend(images.cpu())\n",
        "    test_acc = 100 * correct / total\n",
        "\n",
        "    # matrica zabune\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "\n",
        "\n",
        "    print(\"Classification Report:\\n\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "    #prikaz matrice zabune\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Matrica zabune')\n",
        "    plt.xlabel('Predviđena klasa')\n",
        "    plt.ylabel('Istinita klasa')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "J8jy9wTTPhF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model2, test_loader)"
      ],
      "metadata": {
        "id": "4qr4XOROExt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obično testiranje pojedinih slika (ručno promijeniti path)\n",
        "\n",
        "model2.eval()\n",
        "image_path1=\"/content/drive/My Drive/Testing/meningioma/Te-me_0078.jpg\"\n",
        "image = Image.open(image_path1).convert('RGB')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model2(input_tensor)\n",
        "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "print(\"Predicted class index:\", predicted_class)\n",
        "\n",
        "\n",
        "print(\"Predicted label:\", class_names[predicted_class])"
      ],
      "metadata": {
        "id": "YS_QfctkPozC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam\n",
        "\n",
        "from torchvision import transforms\n",
        "from pytorch_grad_cam import GradCAMPlusPlus\n",
        "from pytorch_grad_cam import GradCAM, GuidedBackpropReLUModel\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
        "\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "YDsTEXkhkhUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_gradcam(model, image_path, target_layer, class_names):\n",
        "    # load i preprocess slike\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = preprocess(image).unsqueeze(0)\n",
        "\n",
        "    # prebacivanje na gpu\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    # kreiranje CAM objekta\n",
        "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
        "    cam.batch_size = 1\n",
        "\n",
        "    # predikcija\n",
        "    input_tensor.requires_grad_()\n",
        "    output = model(input_tensor)\n",
        "    print(\"Raw output (logits):\", output)\n",
        "\n",
        "    # ovo mozes izbrisati\n",
        "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "    print(\"Probabilities:\", probabilities)\n",
        "    predicted_class = output.argmax(dim=1).item()\n",
        "\n",
        "    # Runnaj Grad-CAM\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(predicted_class)])\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "    # Prepare original image for overlay?????\n",
        "    rgb_image = image.resize((224, 224))\n",
        "    rgb_np = np.array(rgb_image).astype(np.float32) / 255.0\n",
        "    cam_image = show_cam_on_image(rgb_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    # Display\n",
        "    plt.imshow(cam_image)\n",
        "    plt.title(f\"Predicted: {class_names[predicted_class]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "image_path = '/content/drive/My Drive/Testing/pituitary/Te-pi_0094.jpg'\n",
        "target_layer = model2.layer3[-1]\n",
        "\n",
        "\n",
        "run_gradcam(model2, image_path, target_layer, class_names)\n"
      ],
      "metadata": {
        "id": "b3VkznJVklm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_gradcam_improved(model, image_path, target_layer, class_names_list, preprocess_fn):\n",
        "    import torch, numpy as np\n",
        "    from PIL import Image\n",
        "    from pytorch_grad_cam import GradCAM\n",
        "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    original_param_grad_states = {name: p.requires_grad for name, p in model.named_parameters()}\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(True)\n",
        "\n",
        "    try:\n",
        "        image_pil = Image.open(image_path).convert('RGB')\n",
        "        #image_pil = image_pil.resize((1024, 1024))\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image not found at {image_path}\")\n",
        "        return\n",
        "\n",
        "    input_tensor = preprocess_fn(image_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
        "    cam.batch_size = 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_logits = model(input_tensor)\n",
        "\n",
        "    probabilities = torch.nn.functional.softmax(output_logits, dim=1)\n",
        "    predicted_class_idx = probabilities.argmax(dim=1).item()\n",
        "    predicted_class_name = class_names_list[predicted_class_idx]\n",
        "\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(predicted_class_idx)])\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    grayscale_cam = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min())\n",
        "    #threshold = np.percentile(grayscale_cam, 95)\n",
        "    #grayscale_cam[grayscale_cam < threshold] = 0\n",
        "\n",
        "    rgb_image = image_pil.resize((224, 224))\n",
        "    rgb_np = np.array(rgb_image).astype(np.float32) / 255.0\n",
        "\n",
        "    cam_image = show_cam_on_image(\n",
        "    rgb_np,\n",
        "    grayscale_cam,\n",
        "    use_rgb=True,\n",
        "    colormap=cv2.COLORMAP_JET,\n",
        "    image_weight=0.5\n",
        ")\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axs[0].imshow(image_pil)\n",
        "    axs[0].set_title(\"Original\")\n",
        "    axs[0].axis('off')\n",
        "    axs[1].imshow(cam_image)\n",
        "    axs[1].set_title(\"Grad-CAM\")\n",
        "    axs[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(cam_image)\n",
        "    plt.title(f\"Grad-CAM | Predicted: {predicted_class_name}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    for name, p in model.named_parameters():\n",
        "        p.requires_grad_(original_param_grad_states.get(name, False))\n",
        "\n",
        "    return grayscale_cam, predicted_class_idx\n"
      ],
      "metadata": {
        "id": "GJZJV8B79uF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prikaz Grad-CAM\n",
        "image_path = '/content/drive/My Drive/Testing/meningioma/Te-me_0135.jpg'\n",
        "target_layer = model2.layer4[-1]\n",
        "grayscale_cam, predicted_class_idx = run_gradcam_improved(\n",
        "    model2,\n",
        "    image_path,\n",
        "    target_layer,\n",
        "    class_names,\n",
        "    preprocess\n",
        ")"
      ],
      "metadata": {
        "id": "qwplndRn-OW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_grad_cam_plus_plus_adapted(model, image_path, target_layer, class_names_list, preprocess_fn):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    original_param_grad_states = {name: p.requires_grad for name, p in model.named_parameters()}\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(True)\n",
        "\n",
        "\n",
        "    try:\n",
        "        image_pil = Image.open(image_path).convert('RGB')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image not found at {image_path}\")\n",
        "\n",
        "        for name, p in model.named_parameters():\n",
        "            p.requires_grad_(original_param_grad_states.get(name, False))\n",
        "        return\n",
        "\n",
        "    input_tensor = preprocess_fn(image_pil).unsqueeze(0).to(device)\n",
        "    cam_obj = GradCAMPlusPlus(model=model, target_layers=[target_layer])\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_logits = model(input_tensor)\n",
        "\n",
        "    print(\"Raw output (logits):\", output_logits)\n",
        "    probabilities = torch.nn.functional.softmax(output_logits, dim=1)\n",
        "    print(\"Probabilities:\", probabilities)\n",
        "    predicted_class_idx = probabilities.argmax(dim=1).item()\n",
        "    predicted_class_name = class_names_list[predicted_class_idx]\n",
        "\n",
        "    # Define targets for CAM\n",
        "    targets_for_cam = [ClassifierOutputTarget(predicted_class_idx)]\n",
        "\n",
        "    # Run Grad-CAM++\n",
        "    grayscale_cam = cam_obj(input_tensor=input_tensor, targets=targets_for_cam)\n",
        "    grayscale_cam = grayscale_cam[0, :] # Get the CAM for the first (and only) image\n",
        "\n",
        "    grayscale_cam = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min())\n",
        "\n",
        "    rgb_image_for_viz = image_pil.resize((224, 224))\n",
        "    rgb_np_for_viz = np.array(rgb_image_for_viz).astype(np.float32) / 255.0\n",
        "\n",
        "    cam_visualization = show_cam_on_image(rgb_np_for_viz, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axs[0].imshow(image_pil)\n",
        "    axs[0].set_title(\"Original\")\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow(cam_visualization)\n",
        "    axs[1].set_title(\"Grad-CAM++\")\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Prikaz heatmape\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(cam_visualization)\n",
        "    plt.title(f\"Grad-CAM++ | Predicted: {predicted_class_name}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    for name, p in model.named_parameters():\n",
        "\n",
        "        p.requires_grad_(original_param_grad_states.get(name, False))\n",
        "    return grayscale_cam, predicted_class_idx\n",
        "\n",
        "\n",
        "target_conv_layer = model2.layer4[-1]\n",
        "test_image_path = '/content/drive/My Drive/Testing/pituitary/Te-pi_0089.jpg' # mjenjaj ručno\n",
        "\n",
        "if not os.path.exists(test_image_path):\n",
        "    print(f\"Kriva slika: {test_image_path}\")\n",
        "else:\n",
        "    print(\"Running Grad-CAM++\")\n",
        "    grayscale_cam, class_index = run_grad_cam_plus_plus_adapted(\n",
        "    model2, test_image_path, target_conv_layer, class_names, preprocess\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EXu6yu4TCTXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rgb_img = np.array(Image.open(image_path).convert('RGB')) / 255.0\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "input_tensor = transform(Image.open(image_path)).unsqueeze(0)\n",
        "print(input_tensor.shape) # shape: [1, 3, 224, 224]\n",
        "input_tensor = input_tensor.to('cuda')"
      ],
      "metadata": {
        "id": "FuRS1CKGSQPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "Lzw8AOCFmW3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "model2.eval()\n",
        "notumor_dir = \"/content/drive/My Drive/Testing/notumor\"\n",
        "\n",
        "notumor_dataset = datasets.ImageFolder(\n",
        "    root=\"/content/drive/My Drive/Testing\",\n",
        "    transform=transform\n",
        ")\n",
        "notumor_label = class_names.index('notumor')\n",
        "\n",
        "# Filtriraj samo za notumor\n",
        "notumor_indices = [i for i, (_, label) in enumerate(notumor_dataset) if label == notumor_label]\n"
      ],
      "metadata": {
        "id": "gAZbbVL2mcrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_indices = notumor_indices[:100]   #100  slika za backgound skup podataka\n",
        "notumor_subset = Subset(notumor_dataset, selected_indices)\n",
        "\n",
        "notumor_loader = DataLoader(notumor_subset, batch_size=50, shuffle=False)\n",
        "\n",
        "background_images, _ = next(iter(notumor_loader))\n",
        "background_images = background_images.to(device)\n",
        "\n",
        "\n",
        "explainer = shap.GradientExplainer(model2, background_images)"
      ],
      "metadata": {
        "id": "Nx8THuSd_sGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/My Drive/Testing/pituitary/Te-pi_0089.jpg\"\n",
        "\n",
        "pil_img     = Image.open(img_path).convert(\"RGB\")\n",
        "test_image  = transform(pil_img).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "sape_lsY-MiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "#prikaz slike\n",
        "def show_image(tensor, title=None):\n",
        "    image = tensor.squeeze(0).cpu().detach().numpy().transpose(1, 2, 0)  # shape: HWC\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean  # de-normalize\n",
        "    image = np.clip(image, 0, 1)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "show_image(test_image)\n"
      ],
      "metadata": {
        "id": "GPpFQR1ImiFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xLWqbEC_JJBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer.shap_values(test_image)   #shap vrijednosti"
      ],
      "metadata": {
        "id": "PwQp79G0mv4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.percentile(np.abs(shap_values), 95)    #5% najznacajnijih vrijednosti\n",
        "shap_values = np.where(np.abs(shap_values) >= threshold, shap_values, 0)\n"
      ],
      "metadata": {
        "id": "chyW5cM6oNZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_image_np = test_image.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model2(test_image)\n",
        "    predicted_class = output.argmax(1).item()\n",
        "shap_values_predicted_class = shap_values[:, :, :, :, predicted_class]\n",
        "shap_values_predicted_class = shap_values_predicted_class.squeeze(0)\n",
        "shap_values_for_plot = shap_values_predicted_class.transpose(1, 2, 0)\n",
        "\n",
        "shap.image_plot([shap_values_for_plot], test_image_np[0])\n"
      ],
      "metadata": {
        "id": "E1mCDQP7mz-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}